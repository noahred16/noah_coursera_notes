# AdvancedLearningAlgorithms
Neural Networks
- Inference (prediction)
- training

Practical advice for building ML system

Final Week - Decision Trees 

# Week 1
## Nerual Networks Intuition
### Video: Welcome! (2 min)
How the Brain Works, Why Neural Networks Took Off
### Video: Neurons and the brain (10 min)

### Video: Demand Prediction (16 min)
Activation funcitons: 
- sigmoid
- ReLU
- tanh functions

The purpose of the activation function in a neural network is to introduce non-linearity to the output of the neuron. By applying a non-linear activation function to the output of each neuron, the neural network becomes capable of learning and modeling much more complex and non-linear relationships between the inputs and outputs

Using logistic regression to predict whether a T-shirt will be a top seller.
Building a neural network. 
- Input layer: vector of features
- Hidden layer: vector of activations
- Output layer: single number, the final prediction
### Video: Example: Recognizing Images (6 min)
Face recognition example. Feature detection. 
### Ungraded External Tool: Ungraded External Tool Have questions, issues or ideas? Join our Community!
[Community Website](https://community.deeplearning.ai/)

## Neural network model
### Video: VideoNeural network layer (9 min)
Demand prediction with four input features.
Hidden layer with three neurons and one output neuron
Logistic regression unit implemented in each neuron (Activation)
Notation for different layers of neural networks
H~2~O

Note Outline:

I. Introduction
A. Fundamental building block of most modern neural networks is a layer of neurons
B. Constructing a layer of neurons is important to form a large neural network

II. Building a Layer of Neurons
A. Example of demand prediction with four input features
B. Hidden layer with three neurons and one output neuron
C. Logistic regression unit implemented in each neuron
D. Activation value determined by logistic function
E. Notation for different layers of neural networks
F. Output of layer 1 becomes input to layer 2

III. Computation of Output Layer
A. Input to layer 2 is the output of layer 1
B. Output layer has a single neuron
C. Computation of activation value using sigmoid function
D. Superscript in square brackets 2 for notation of output layer

IV. Binary Prediction
A. Optional step for binary prediction
B. Thresholding at 0.5 for final prediction

V. Conclusion
A. Recap of neural network computation
B. Importance of layering for complex neural networks
C. Next video will showcase more examples to enhance understanding.

### Video: VideoMore complex neural networks (8 min)
Input layer is layer 0. A NN with 3 layers has a two hidden layers and one output layer.

### Video: VideoInference: making predictions (forward propagation) (5 min)


### Lab: Neurons and Layers (10 min)


## Practice quiz: Neural network model
## TensorFlow implementation
## Practice quiz: TensorFlow implementation
## Neural network implementation in Python
## Practice quiz: Neural network implementation in Python
## Speculations on artificial general intelligence (AGI)
## Vectorization (optional)
## Practice Lab: Neural networks

# Week 2



# Week 3 

# Week 4 

`echo nice`

also cool

| Syntax | Description |
| ----------- | ----------- |
| Header | Title |
| Paragraph | Text |

---

nice

```
{
  "firstName": "John",
  "lastName": "Smith",
  "age": 25
}
```


Neural networks intuition
Video: VideoWelcome!
. Duration: 2 minutes2 min
Video: VideoNeurons and the brain
. Duration: 10 minutes10 min
Video: VideoDemand Prediction
. Duration: 16 minutes16 min